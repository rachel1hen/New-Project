name: Zonos TTS (Inline Inference)

on:
  workflow_dispatch:

jobs:
  zonos-inference:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo (optional)
      uses: actions/checkout@v3

    - name: Install system dependencies
      run: |
        #sudo apt-get update
        sudo apt-get install -y espeak-ng #python3-pip git

    - name: Clone and install Zonos
      run: |
        git clone https://github.com/Zyphra/Zonos.git
        cd Zonos
        pip install --upgrade pip
        pip install -e .
        pip install torch  # CPU version

    - name: Run Zonos TTS inline
      run: |
        cp female_random_podcast.wav Zonos/
        cd Zonos
        
        python - << 'EOF'
        import torch
        import torchaudio
        import os
        from zonos.model import Zonos
        from zonos.conditioning import make_cond_dict
        
        device = torch.device("cpu")
        model = Zonos.from_pretrained("Zyphra/Zonos-v0.1-transformer", device=device)
        
        speaker_path = "female_random_podcast.wav"
        
        
        # ðŸ” Check file exists
        assert os.path.exists(speaker_path), f"âŒ File not found: {speaker_path}"
        print("âœ… Speaker file exists:", speaker_path)
        
        # ðŸ” Try loading waveform
        try:
            waveform, sr = torchaudio.load(speaker_path)
            print("âœ… Loaded waveform shape:", waveform.shape)
            print("ðŸ“¢ Sample rate:", sr)
            wav, sampling_rate = torchaudio.load("female_random_podcast.wav")
            speaker = model.make_speaker_embedding(wav, sampling_rate)
        
        except Exception as e:
            print("âŒ Failed to load speaker audio:", e)
            speaker_path = None  # fallback to default voice
        
        # âœ… Build conditioning
        cond_dict = make_cond_dict(
            text="This is voice-cloned audio from a podcast speaker.",
            speaker=speaker,
            language="en-us",
            emotion="happy" 
        )
        
        conditioning = model.prepare_conditioning(cond_dict)
        codes = model.generate(conditioning)
        wavs = model.autoencoder.decode(codes).cpu()
        torchaudio.save("output.wav", wavs[0], model.autoencoder.sampling_rate)
        EOF
    - name: Upload generated audio
      uses: actions/upload-artifact@v4
      with:
        name: zonos-tts-output
        path: Zonos/output.wav
